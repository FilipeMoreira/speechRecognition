<!DOCTYPE html>
<html>
<head>
	<title>Test</title>
	<style type="text/css">
		.btn {
			padding: 4px;
			border: 1px solid #000;
			background-color: #ddd;
		}
	</style>
	<script
	  src="https://code.jquery.com/jquery-3.3.1.min.js"
	  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
	  crossorigin="anonymous"></script>
	</head>
<body>
<div id='btn-google'>Google Speech</div>
<div id='google-text'></div>


<div id='btn-start' class='btn'>Start</div>
<div id='btn-stop' class='btn'>Stop</div>

<div id='text'></div>

<script type="text/javascript">
	try {
		var SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
		var recognition = new SpeechRecognition();
		recognition.lang = 'pt-BR';
		recognition.maxAlternatives = 5;

		var continuous;

		recognition.onstart = function() { 
		  console.log('Reconhecimento de voz ativado.');
		}

		recognition.onspeechend = function() {
		  console.log('Silencio detectado. Reconhecimento de voz desativado.');
		}

		recognition.onerror = function(event) {
		  if(event.error == 'no-speech') {
		    console.log('Nenhuma fala foi detectada.');
			}
		}

		recognition.onend = function(event) {
			if (continuous) recognition.start();
		}

		recognition.onresult = function(event) {

		  // event is a SpeechRecognitionEvent object.
		  // It holds all the lines we have captured so far. 
		  // We only need the current one.
		  var current = event.resultIndex;

		  // Get a transcript of what was said.
		  var transcript = event.results[current][0].transcript;

		  // Add the current transcript to the contents of our Note.
		$("#text").html($("#text").html() + "<br>" +transcript);
		translateToEnglish(transcript);
		console.log(event.results);
		$('#btn-stop').css({
		  	backgroundColor: "#ddd"
		  });
		$('#btn-start').css({
		  	backgroundColor: "#ddd"
		  });
		}

		$('#btn-start').click( function(e) {
			continuous = true;
		  recognition.start();

		  $('#btn-start').css({
		  	backgroundColor: "#999"
		  });
		  $('#btn-stop').css({
		  	backgroundColor: "#ddd"
		  });
		});

		$('#btn-stop').click( function(e) {
			continuous = false;
		  recognition.stop();

		  $('#btn-stop').css({
		  	backgroundColor: "#999"
		  });
		  $('#btn-start').css({
		  	backgroundColor: "#ddd"
		  });
		});
	} catch(e) {
		console.error(e);
		$("#text").html($("#text").html() + "<br>ERRO: "+e);
	}

	function translateToEnglish(value) {

		$.post("https://translation.googleapis.com/language/translate/v2",
			{
				key: "AIzaSyASfEsrO2CELhU3QohVw6HlOJtpWGhLLNI",
				source: "pt",
				target: "en",
				q: value
			}
		).done(function(data) {
			$("#text").html($("#text").html() + "<br><i>" +data.data.translations[0].translatedText+"</i>");
		});

	}

	$(document).ready(function() {

		$("#btn-google").click(function() {

			navigator.mediaDevices.getUserMedia({ audio: true })
			  .then(stream => {
			    const mediaRecorder = new MediaRecorder(stream);
			    mediaRecorder.start();

			    const audioChunks = [];
			    mediaRecorder.addEventListener("dataavailable", event => {
			      audioChunks.push(event.data);
			    });

			    mediaRecorder.addEventListener("stop", function() {
			      const audioBlob = new Blob(audioChunks);
			      const audioUrl = URL.createObjectURL(audioBlob);
			      const audio = new Audio(audioUrl);
			      audio.play();

			      googleSpeech(audio);

			    });

			    setTimeout(() => {
			      mediaRecorder.stop();
			    }, 3000);
			  });

		});

	});

	googleSpeech(audio) {
		console.log("here");
		$.post("https://speech.googleapis.com/v1/speech:recognize?key=AIzaSyASfEsrO2CELhU3QohVw6HlOJtpWGhLLNI",
			{
				{
					"config": {
					"encoding": "LINEAR16",
					"sampleRateHertz": 16000,
					"languageCode": "pt-BR",
					"enableWordTimeOffsets": false
				},
					"audio": {
						"content": audio
	  				}
				}
			}
		).done(function(data) {
      		$("#google-text").text(data.results.alternatives[0].transcript);
		});
	}

</script>

</body>
</html>
